~~~~~~~~~~~~~~~~~~~~~~
* 이진분류
* 벡터화의 필요성
* 신경망계산법 2 가지 : Backward Propagation & Forward Propagation 
* logistic regression
* 퍼셉트론 vs. 신경망 & 활성화 함수의 필요성
~~~~~~~~~~~~~~~~~~~~~~~

## Binary_Classification<br>

1. sample m 개 -> m번 for loop?<br>
  => deep neural network 에서는 vectorization 으로 압축<br>
2.신경망 계산<br>
  - Forward Propagation<br>
  - Backward Propagation<br>


## Logistic Regression<br>

* 'regression'?
-종속변인과 독립변인의 관계를 추정하기 위해(y=f(x)) 만듬

-데이터의 실측치와 모델의 추정치 사이의 잔차
  (데이터의 실측지와 모델의 예측치 사이의 차이가 '평균'으로 회귀 하는 것 )가 *정규분포*이면서 *독립분포*여야 한다
  
  즉, 독립적이지 않다면(패턴을 가진다) 문제를 가진다
    ?어떤 문제?



#### 퍼셉트론 과 신경망의 차이<br>
  퍼셉트론의 활성화 함수는 상대적으로 단순 ( 신경망 vice versa)<br>
  퍼셉트론은 하나의 layer를 의미

#### 활성화함수의 등장<br>
##### 활성화 함수 : 입력신호의 총합을 그대로 사용하지 않고 출력신호로 변환시킨다<br> (즉, 입력신호의 총합이 활성화를 일으키는지 아닌지를 결정)<br>

##### 활성화 함수 왜 필요한가 ? <br>
1.만약 Hidden Layer 의 선형적 과정(y = ax + b )이 계속 반복 된다면<br>
  어차피 전체 model 은 선형 -> 비효율적 <br> 

2.가중치(W)가 무한하게 증가하는 것을 방지 <br>

3.Optimization에 적합한 데이터를 생성하게끔 해준다.<br>
https://www.quora.com/Why-do-neural-networks-need-an-activation-function<br>

#### 활성화 함수: 입력신호의 총합을 그대로 사용하지 않고 출력신호로 변환시킨다<br> (즉, 입력신호의 총합이 활성화를 일으키는지 아닌지를 결정)<br>

#### 활성화 함수의 종류<br>

> 시그모이드 함수  : 비선형 함수 (신경망에 + 비선형 함수;simgoid)<br>
<br>
> ReLU 함수 : 입력이 0을 넘으면 그 입력을 그대로 출력하고 0 이하이면 0을 출력하는 함수입니다.<br>
